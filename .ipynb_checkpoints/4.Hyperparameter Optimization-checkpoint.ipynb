{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We focused on increasing the number of attributes the model uses. We saw how, in general, adding more attributes generally lowered the error of the model. This is because the model is able to do a better job identifying the living spaces from the training set that are the most similar to the ones from the test set. However, we also observed how using all of the available features didn't actually improve the model's accuracy automatically and that some of the features were probably not relevant for similarity ranking. We learned that selecting relevant features was the right lever when improving a model's accuracy, not just increasing the features used in the absolute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we'll focus on the impact of increasing k, the number of nearby neighbors the model uses to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv(\"dc_airbnb_train.csv\")\n",
    "test_df = pd.read_csv(\"dc_airbnb_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>maximum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.596544</td>\n",
       "      <td>-0.249467</td>\n",
       "      <td>-0.439151</td>\n",
       "      <td>-0.546858</td>\n",
       "      <td>125.0</td>\n",
       "      <td>-0.341375</td>\n",
       "      <td>-0.016604</td>\n",
       "      <td>4.579650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.596544</td>\n",
       "      <td>-0.249467</td>\n",
       "      <td>0.412923</td>\n",
       "      <td>-0.546858</td>\n",
       "      <td>85.0</td>\n",
       "      <td>-0.341375</td>\n",
       "      <td>-0.016603</td>\n",
       "      <td>1.159275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.095499</td>\n",
       "      <td>-0.249467</td>\n",
       "      <td>-1.291226</td>\n",
       "      <td>-0.546858</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-0.341375</td>\n",
       "      <td>-0.016573</td>\n",
       "      <td>-0.482505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.596544</td>\n",
       "      <td>-0.249467</td>\n",
       "      <td>-0.439151</td>\n",
       "      <td>-0.546858</td>\n",
       "      <td>209.0</td>\n",
       "      <td>0.487635</td>\n",
       "      <td>-0.016584</td>\n",
       "      <td>-0.448301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.393004</td>\n",
       "      <td>4.507903</td>\n",
       "      <td>1.264998</td>\n",
       "      <td>2.829956</td>\n",
       "      <td>215.0</td>\n",
       "      <td>-0.065038</td>\n",
       "      <td>-0.016553</td>\n",
       "      <td>0.646219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accommodates  bedrooms  bathrooms      beds  price  minimum_nights  \\\n",
       "0     -0.596544 -0.249467  -0.439151 -0.546858  125.0       -0.341375   \n",
       "1     -0.596544 -0.249467   0.412923 -0.546858   85.0       -0.341375   \n",
       "2     -1.095499 -0.249467  -1.291226 -0.546858   50.0       -0.341375   \n",
       "3     -0.596544 -0.249467  -0.439151 -0.546858  209.0        0.487635   \n",
       "4      4.393004  4.507903   1.264998  2.829956  215.0       -0.065038   \n",
       "\n",
       "   maximum_nights  number_of_reviews  \n",
       "0       -0.016604           4.579650  \n",
       "1       -0.016603           1.159275  \n",
       "2       -0.016573          -0.482505  \n",
       "3       -0.016584          -0.448301  \n",
       "4       -0.016553           0.646219  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we vary the features that are used in the model, we're affecting the data that the model uses. On the other hand, varying the k value affects the behavior of the model independently of the actual data that's used when making predictions. In other words, we're impacting how the model performs without trying to change the data that's used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Values that affect the behavior and performance of a model that are unrelated to the data that's used are referred to as **hyperparameters**. The process of finding the optimal hyperparameter value is known as [hyperparameter optimization](https://en.wikipedia.org/wiki/Hyperparameter_optimization)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple but common hyperparameter optimization technique is known as [grid search](https://en.wikipedia.org/wiki/Hyperparameter_optimization#Grid_search), which involves:\n",
    "\n",
    "* selecting a subset of the possible hyperparameter values,\n",
    "* training a model using each of these hyperparameter values,\n",
    "* evaluating each model's performance,\n",
    "* selecting the hyperparameter value that resulted in the lowest error value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search essentially boils down to evaluating the model performance at different k values and selecting the k value that resulted in the lowest error. While grid search can take a long time when working with large datasets, the data we're working with in this project is small and this process is relatively quick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[26364.92832764505,\n",
       " 15100.52246871445,\n",
       " 14579.597901655923,\n",
       " 16212.300767918088,\n",
       " 14090.011649601822]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_params = [1,2,3,4,5]\n",
    "mse_values = []\n",
    "features = [\"accommodates\",\"bedrooms\",\"bathrooms\",\"number_of_reviews\"]\n",
    "\n",
    "for i in hyper_params:\n",
    "    knn = KNeighborsRegressor(n_neighbors=i, algorithm=\"brute\", metric=\"euclidean\")\n",
    "    knn.fit(train_df[features], train_df[\"price\"])\n",
    "    predictions = knn.predict(test_df[features])\n",
    "    mse = mean_squared_error(test_df[\"price\"], predictions)\n",
    "    mse_values.append(mse)\n",
    "mse_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " As we increased the k value from 1 to 5, the MSE value fell from approximately 26364 to approximately 14090"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[26364.92832764505,\n",
       " 15100.52246871445,\n",
       " 14579.597901655923,\n",
       " 16212.300767918088,\n",
       " 14090.011649601822,\n",
       " 13657.290671217292,\n",
       " 14288.273896589353,\n",
       " 14853.448183304892,\n",
       " 14670.831907751512,\n",
       " 14642.451478953355,\n",
       " 14734.071380889252,\n",
       " 14854.556669510808,\n",
       " 14733.16190399257,\n",
       " 14777.975894453346,\n",
       " 14771.124646694478,\n",
       " 14870.178509847838,\n",
       " 14832.598509630716,\n",
       " 14783.592968300116,\n",
       " 14775.594716988267,\n",
       " 14676.947986348125]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# expand grid search all the way to a k value of 20\n",
    "\n",
    "hyper_params = range(1,21)\n",
    "\n",
    "mse_values = []\n",
    "features = [\"accommodates\",\"bedrooms\",\"bathrooms\",\"number_of_reviews\"]\n",
    "\n",
    "for i in hyper_params:\n",
    "    knn = KNeighborsRegressor(n_neighbors=i, algorithm=\"brute\", metric=\"euclidean\")\n",
    "    knn.fit(train_df[features], train_df[\"price\"])\n",
    "    predictions = knn.predict(test_df[features])\n",
    "    mse = mean_squared_error(test_df[\"price\"], predictions)\n",
    "    mse_values.append(mse)\n",
    "mse_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we increased the k value from 1 to 6, the MSE value decreased from approximately 26364 to approximately 13657. However, as we increased the k value from 7 to 20, the MSE value didn't decrease further but instead hovered between approximately 14288 and 14870. This means that the optimal k value is 6, since it resulted in the lowest MSE value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This pattern is something we'll notice while performing grid search across other models as well. As we increase k at first, the error rate decreases until a certain point, but then rebounds and increases again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# scatter plot\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(hyper_params, mse_values)\n",
    "plt.xticks(range(1,21))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may have noticed that the general workflow for finding the best model is:\n",
    "\n",
    "* select relevant features to use for predicting the target column.\n",
    "* use grid search to find the optimal hyperparameter value for the selected features.\n",
    "* evaluate the model's accuracy and repeat the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k value that obtained the lowest MSE value using two features\n",
    "two_features = ['accommodates', 'bathrooms']\n",
    "hyper_params = [x for x in range(1,21)]\n",
    "two_mse_values = list()\n",
    "\n",
    "for hp in hyper_params:\n",
    "    knn = KNeighborsRegressor(n_neighbors=hp, algorithm='brute')\n",
    "    knn.fit(train_df[two_features], train_df['price'])\n",
    "    predictions = knn.predict(test_df[two_features])\n",
    "    mse = mean_squared_error(test_df['price'], predictions)\n",
    "    two_mse_values.append(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5: 14790.314266211606}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_hyp_mse = dict()\n",
    "\n",
    "two_lowest_mse = two_mse_values[0]\n",
    "two_lowest_k = 1\n",
    "\n",
    "for i, value in enumerate(two_mse_values):\n",
    "    if value < two_lowest_mse:\n",
    "        two_lowest_mse = value\n",
    "        two_lowest_k = hyper_params[i]\n",
    "        \n",
    "two_hyp_mse[two_lowest_k] = two_lowest_mse\n",
    "two_hyp_mse  # k value that obtained the lowest MSE value using two features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k value that obtained the lowest MSE value using three features\n",
    "three_features = ['accommodates', 'bathrooms', 'bedrooms']\n",
    "\n",
    "three_mse_values = dict()\n",
    "\n",
    "for hp in hyper_params:\n",
    "    knn = KNeighborsRegressor(n_neighbors=hp, algorithm='brute')\n",
    "    knn.fit(train_df[three_features], train_df['price'])\n",
    "    predictions = knn.predict(test_df[three_features])\n",
    "    mse = mean_squared_error(test_df['price'], predictions)\n",
    "    three_mse_values[hp] = mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{7: 13518.769009310208}\n"
     ]
    }
   ],
   "source": [
    "three_hyp_mse = min(three_mse_values, key = three_mse_values.get)\n",
    "print({three_hyp_mse:three_mse_values[three_hyp_mse]})  # k value that obtained the lowest MSE value using three features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model, which used the accommodates and bathrooms columns, was able to achieve an MSE value of approximately 14790. The second model, which added the bedrooms column, was able to achieve an MSE value of approximately 13522.9, which is even lower\n",
    "\n",
    "This demonstrates that using just one lever to find the best model isn't enough and we really want to use both levers in conjunction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
